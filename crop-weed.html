<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Crop & Weed Detection | Portfolio</title>
  <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@700&family=Share+Tech+Mono&family=VT323&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="crop-weed.css">
</head>
<body>

<!-- Hero / Project Header -->
<section class="hero-box">
  <div class="hero-content">
    <div class="hero-left">
      <h1 class="hero-name" data-text="Crop & Weed Detection">Crop & Weed Detection</h1>
      <h2 class="ai-subtitle">YOLOv10b vs CNN Model Comparison</h2>
      <p>This project focuses on detecting crops and weeds in agricultural fields using AI. YOLOv10b achieved <strong>97.11%</strong> accuracy, while CNN achieved <strong>89.5%</strong>.</p>
    </div>
    <div class="hero-right">
      <img src="image-6.jpg" alt="Crop & Weed Detection" class="hero-image">
      <div class="buttons">
        <a href="index.html" class="btn"><span>Back to Portfolio </span></a>
        <a href="https://github.com/harishkadhir/CropAndWeedDetection_HarishKadhir.git" target="_blank" class="btn github-btn">
          <span>GitHub</span>
        </a>
      </div>
    </div>
  </div>
</section>

<!-- Content Section -->
<section class="content-section">
  <div class="content-inner">

    <h2 class="glitch-heading" data-text="Overview">Overview</h2>
    <p>Crop and Weed Detection is a computer vision project aimed at identifying and distinguishing between crops and weeds in agricultural fields. Using state-of-the-art machine learning techniques, this project automates plant detection, helping farmers optimize crop management practices.</p>

    <h2 class="glitch-heading" data-text="Requirements">Requirements</h2>
    <p>To run Crop and Weed Detection, you will need:</p>
    <ul>
      <li>Python 3.x</li>
      <li>ultralytics</li>
      <li>OpenCV</li>
    </ul>
    <pre>!pip install ultralytics opencv-python</pre>

    <h2 class="glitch-heading" data-text="Dataset">Dataset</h2>
    <p>The dataset used consists of labeled images of crops and weeds collected from agricultural fields. Images include varying lighting conditions, angles, and backgrounds to make the model robust. Data augmentation techniques such as rotation, flipping, and scaling were applied to increase dataset diversity.</p>

    <h2 class="glitch-heading" data-text="Model Architecture">Model Architecture</h2>
    <p>The project compares two models:</p>
    <ul>
      <li><strong>YOLOv10b:</strong> Real-time object detection model with high accuracy and fast inference time.</li>
      <li><strong>CNN:</strong> Convolutional Neural Network model for image classification of crops and weeds.</li>
    </ul>

    <h2 class="glitch-heading" data-text="Training Process">Training Process</h2>
    <p>The models were trained using labeled datasets with appropriate train-test splits. Hyperparameters such as learning rate, batch size, and epochs were tuned for optimal performance. YOLOv10b was trained for object detection, while CNN was trained for image classification. Early stopping and checkpointing ensured the best model was saved.</p>

    <h2 class="glitch-heading" data-text="How it Works">How it Works</h2>
    <p>The project leverages deep learning models trained on labeled datasets of images containing crops and weeds. The model can recognize patterns to classify crops and weeds. It also supports real-time detection using a camera via OpenCV, allowing farmers to monitor fields instantly.</p>

    <h2 class="glitch-heading" data-text="Results">Results</h2>
    <p>After running the detection, results are displayed on-screen. The program also generates an output image highlighting the detected crops and weeds. YOLOv10b achieved <strong>97.11%</strong> accuracy, outperforming CNN which achieved <strong>89.5%</strong>.</p>
    <img src="cropres.jpeg" alt="Detection Result" class="result-image">

    <h2 class="glitch-heading" data-text="Challenges">Challenges</h2>
    <p>During development, challenges included varying lighting conditions, occluded plants, and similarity between certain crops and weeds. Preprocessing and data augmentation helped overcome these issues, improving model robustness.</p>

    <h2 class="glitch-heading" data-text="Future Improvements">Future Improvements</h2>
    <ul>
      <li>Expand dataset with more crop and weed types.</li>
      <li>Optimize models for mobile deployment.</li>
      <li>Implement a web-based dashboard for live monitoring.</li>
      <li>Use additional AI techniques like semantic segmentation for better accuracy.</li>
    </ul>

  </div>
</section>

<footer>
  <p>Â© 2025 | Harish Kadhir SJ</p>
</footer>

</body>
</html>
